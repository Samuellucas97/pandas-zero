{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualization_seminar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUWprNFrL4dp",
        "colab_type": "text"
      },
      "source": [
        "# Data analysis and presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Fgl4oFL4dy",
        "colab_type": "text"
      },
      "source": [
        "## Preparation before analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHpX-aUaL4d1",
        "colab_type": "text"
      },
      "source": [
        "Everytime you want to explore and extract information from a dataset, first you need to understand what kind of information it's possible obtain with the available data. In general, data is classified as:\n",
        "\n",
        "**Numerical:** Also known as quantitative data, are datasets that represents counts or measures, like age, height or weight. Is possible with this type of data do statistical analysis and determine mean, median, standart deviation, etc. This data are also divided into two groups:\n",
        "\n",
        "\n",
        "*   **Discrete:** Represented by integer numbers (ex: Age).\n",
        "*   **Continuous:** Can assume any real value (ex: Weight, height).\n",
        "\n",
        "**Categorical Data:** Also known as qualitaties, are the datasets that has non-numerical caracteristcs, they can be:\n",
        "\n",
        "\n",
        "*   **Ordinal:** Type of data that can be ordered in some way that makes sense (ex.: Age range, stages of a disease, dates).\n",
        "*   **Nominal:** Are basically defined by names, with no specif order (ex: Blood type, race, sex, yes/no).\n",
        "\n",
        "\n",
        "![alt text](\n",
        "https://cdn.shopify.com/s/files/1/1334/2321/articles/Picture1.png?v=1497575369)\n",
        "Source: [Data analysis](https://legac.com.au/blogs/further-mathematics-exam-revision/further-mathematics-unit-3-data-analysis-types-of-data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2leZMAVKL4d8",
        "colab_type": "text"
      },
      "source": [
        "### Invalid or missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO_qHTn0L4eB",
        "colab_type": "text"
      },
      "source": [
        "Everytime a dataset is collected and sent to analysis, a number of activities must to be done before is possible to extract any relevat and reliable information. In the previous topics, we've seen how to initialize the data exploration with Pandas. However, after obtaining our dataframe, it's needed to check the integrity of our data and clean them before we can do any analysis. According to [IBM Data Analytics](https://www.ibm.com/cloud/blog/ibm-data-catalog-data-scientists-productivity), 80% of the given time to an available dataset for analysis is spent cleaning up the data.\n",
        "\n",
        "Data treatment is an important stage in data cleaning (if some data can't be used in the analysis, it's missing). We're going to use a small [data set](https://raw.githubusercontent.com/dataoptimal/posts/master/data%20cleaning%20with%20python%20and%20pandas/property%20data.csv), while big enought to understand how to deal with missing data.\n",
        "\n",
        "Run the cells below to import the example data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_y0lkgdL4eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdGUX6EdL4eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data = pd.read_csv('https://raw.githubusercontent.com/dataoptimal/posts/master/data%20cleaning%20with%20python%20and%20pandas/property%20data.csv',sep=',')\n",
        "missing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF60BY6qL4ee",
        "colab_type": "text"
      },
      "source": [
        "It is possible to notice the invalid data in the data frame above. Pandas can detect some invalid or missing values. For this data, it uses the label `NaN`.\n",
        "\n",
        "The `isnull()` is an specific Pandas method to identify missing value in a series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdwJOwPQL4eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data['NUM_BATH'].isnull()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T7-KkV2L4es",
        "colab_type": "text"
      },
      "source": [
        "See that the `isnull()` method returns `True` always that exists a missing value at the evaluated field.\n",
        "\n",
        "Is not practical to aply the `isnull()` method manualy for each characteristic. To evaluate the number os missing values on each characteristc just combine the `sum()` method with the result of the `isnull()` method aplyied to all the data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-d43AbeL4ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU4VnSmFL4e2",
        "colab_type": "text"
      },
      "source": [
        "Not always Pandas will be able to indentify an invalid data. On our exemple there's an invalid data `'na'` on the series that represents the characteristic `NUM_BEDROOMS` and another invalid data `'--'` on the series that represents the characteristic `SQ_FT`. \n",
        "\n",
        "On this case, we can use the `unique()` or `value_counts()` methods to see the values existents on a series:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQ0LORTL4e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[\"NUM_BEDROOMS\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmqe1iT8lmNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[\"NUM_BEDROOMS\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWfWmwAsL4fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[\"SQ_FT\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzghO0QIL4fH",
        "colab_type": "text"
      },
      "source": [
        "Another invalid data case happens when a data differente from what is expected to an characteristic is found. The column `OWN_OCCUPIED` should contain values ​​in the format `Y` or `N`. However, in one of the lines is found the value `12`, that have no realtion with the other expected values.\n",
        "\n",
        "On this case, we can use the `isin()` and `all()` methods, too see if all the values from a series respect the **domain** off expected values to that series.\n",
        "\n",
        "* The `isin()` method evaluates if an nominal data is in a list of options, converting the original series in a values series of `True`(case the value is in) or `False` (otherwise).\n",
        "* The `all()` method evaluates if all the new series of `True` and `False` values are equal to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDw9x213mLbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[\"OWN_OCCUPIED\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jg9PVneL4fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "domain_condition = missing_data[\"OWN_OCCUPIED\"].isin([\"Y\",\"N\"])\n",
        "all(domain_condition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIC4XZ5bPNGS",
        "colab_type": "text"
      },
      "source": [
        "To indentify which data from the series `\"OWN_OCCUPIED\"` desobey the informed condition, we can invert the search condition using the `~` operator (read as not):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJHXm9bVL4fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[~domain_condition]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qNSg1qIL4fY",
        "colab_type": "text"
      },
      "source": [
        "## Starting the analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP9JFgyKL4fa",
        "colab_type": "text"
      },
      "source": [
        "The data from this part of the Tutorial will be loaded from an URL \n",
        "\n",
        "Let's let pandas download the dataset directly, informing only the it's URL where it's located. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IvRWAQofrpLA",
        "colab": {}
      },
      "source": [
        "url_data = 'http://bit.ly/2cLzoxH'\n",
        "data = pd.read_csv(url_data)\n",
        "data.head(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcl-3Y4RubSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Take a quick look at the data structure\n",
        "#data.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhvfKoZU-hB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data[\"continent\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPRXqHsVL4fh",
        "colab_type": "text"
      },
      "source": [
        "Once there's concluded the data cleaning, the first set of tools that we can use to analyze are the **descriptive statistics**\n",
        "\n",
        "Pandas offer the main **central** and **dispersion** measures, that we can apply to any numeric data series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwgOpZdLL4fj",
        "colab_type": "text"
      },
      "source": [
        "### Central Measures\n",
        "\n",
        "![alt text](https://media.proprofs.com/images/discuss/user_images/153336/9973678110.jpg) Source:  [Measure of Central Tendency](https://www.proprofs.com/discuss/q/273982/which-of-the-following-is-not-measure-central-tendency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNGpvCHgL4fl",
        "colab_type": "text"
      },
      "source": [
        "**Mean**: The sum of all the measures devided by the number of observations on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZA059wL4fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0dlTWlOL4fr",
        "colab_type": "text"
      },
      "source": [
        "**Median**: The middle value that separates the bigger half from the smallest half on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6BTNx0hL4fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].median()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eekJ8I1UL4fx",
        "colab_type": "text"
      },
      "source": [
        "**Mode**: The value(s) that appear more frequently on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS-E95i1L4fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].mode()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFAtr7ULL4f4",
        "colab_type": "text"
      },
      "source": [
        "### Dispersion Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us_pPKC4L4f5",
        "colab_type": "text"
      },
      "source": [
        "**Variance**: Indicates the data scattering in a series.\n",
        "\n",
        "Is calculated as the mean distance of each value from an series to the series's mean. Each distance is raised square during the sum, so that positive and negative distantances do not cancel each other. Becouse of that, the magnitude order do not match with the ones from the data of the series.\n",
        "\n",
        "A low variance indicates that the values from the series tend to be closer to the mean. A high variance indicates that the values are scattering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXQWRiJL4f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].var()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr48uJXwL4gB",
        "colab_type": "text"
      },
      "source": [
        "**Standard deviation**: Square root of variance. Retains all its properties, but presents the same magnitude order as the series data: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i38lCnbZL4gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12tsWb4bL4gH",
        "colab_type": "text"
      },
      "source": [
        "**Quantiles**: They partition the ordered series values. A 25% quantile indicates that 25% of the series values ​​are less than that quantile. By convention, *** quartiles *** are the 25%, 50% and 75% quantiles, also known as first, second and third quartiles:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb4SSYvdL4gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].quantile(0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0A_xffYL4gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_quartile = data.query(f\"year < {data['year'].quantile(0.25)}\")\n",
        "first_quartile.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TNF9SjNIL4gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3FBtCgHu8P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing for others quartiles\n",
        "\n",
        "#data[\"year\"].quantile(0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JMjEU2YvR1F",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJaB2JezuyHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#second_quartile = data.query(f\"year < {data['year'].quantile(0.5)}\")\n",
        "#second_quartile.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5n8HvrYL4gc",
        "colab_type": "text"
      },
      "source": [
        "### Other methods of descriptive statistcs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4whhc4L4gd",
        "colab_type": "text"
      },
      "source": [
        "* `describe()`: Brings together many descriptive measures about the data, including the `count()`, `min()` and `max()` methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu-NRWZrL4gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weIrWGPeL4gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8D8V-sVL4go",
        "colab_type": "text"
      },
      "source": [
        "* `nique()`: Informs the number of distinct values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHQAU6xOL4gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiYwdjY_L4gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsxPrw_gL4gx",
        "colab_type": "text"
      },
      "source": [
        "* `sort_values()`: Sorts the values of an `DataFrame` or `Series`, in ascending or descending order. When using the `sort_values()` method of the `DataFrame`, We can specify multiple columns to sort. In this case, ties on the first column will be solved on the second column, and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_osXt0cL4g0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].sort_values().head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL7kQVvpL4g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.sort_values(by=['year','country'],ascending=False).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma_laG1zyPkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.sort_values(by=['year','lifeExp'],ascending=True).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwABO3JgL4g-",
        "colab_type": "text"
      },
      "source": [
        "## Data Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ni0vgAIHiFI"
      },
      "source": [
        "The analysis of central measures and dispersion of the `DataFrame` is usually deepened by visualizing the data series.\n",
        "\n",
        "To start, let's load the necessary libraries:\n",
        "- `matplotlib` is a library that serves exclusively to create graphics;\n",
        "- `seaborn` is a library designed to create statistical graphs in Python. \n",
        "It is built on based of Matplotlib and is integrated with Pandas data structures.\n",
        "\n",
        "By convention, we only load the `pyplot` module from the `matplotlib` library and call it `plt`.\n",
        "\n",
        "In the case of `seaborn`, we load the entire library, call it `sns` and use its `set()` method to put its initial settings into effect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_PDGogQn3QS",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kIbzhXQ000XQ"
      },
      "source": [
        "### Histograms\n",
        "\n",
        "With the commands offered by Pandas it is easy to construct a histogram. However, it is necessary to understand exactly what is being built.\n",
        "\n",
        "In the excerpt below we say that from the `dados` set we will use the `lifeExp` column, which shows the life expectancy per year.\n",
        "\n",
        "With the `hist(bins = 100)` method we will have the histogram with 100 different ranges of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NwLUT8xptz_9",
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JKLxZZdx4sLT"
      },
      "source": [
        "Below we can see the (extreme) effect of building a histogram with few ranges of values (only two, in this case).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ooQ_pCJKuMX-",
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lyarbic35AgQ"
      },
      "source": [
        "The case below is exactly the reverse of what was shown above: many ranges of values (1000 in the graph below) make understanding very difficult."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aj6a95vvu4Ie",
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCdxMt0PzARd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ploting the data analysis of the feature 'year' shows that not all information can be analyzed using a histogram\n",
        "#data[\"year\"].hist(bins=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-G0sC0zyAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data[\"year\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AqnPTNI0P7vL"
      },
      "source": [
        "The standard Pandas histogram is basic and only serves for a quick look at the distribution of the data, but it does not tell the whole story.\n",
        "\n",
        "In addition to there being no names on the X and Y axes, there is a region of the X axis being presented even if there is no data in it.\n",
        "\n",
        "We can solve this by configuring the histogram using the following parameters:\n",
        "  - `xlabelsize` and `ylabelsize` dictate the font size on the axes;\n",
        "  - `xlabel` and `ylabel` are the methods that change the title of the axis and the size of that text;\n",
        "  - `xlim` is also a method and determines the lower and upper limits of the horizontal axis.\n",
        "\n",
        "Below we can see how to customize the information that appears in the histogram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7AsoMmeHP_kh",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=100, grid=False, xlabelsize=12, ylabelsize=12)\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution\", fontsize=17)\n",
        "plt.xlim([22.0,90.0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20_-XPE6L4hd",
        "colab_type": "text"
      },
      "source": [
        "Although it is convenient to use the `hist()` method directly from a series, the `seaborn` `distplot()` method is much more powerful.\n",
        "\n",
        "In addition to presenting a histogram of the data, `distplot()` estimates a **probability distribution** of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4bINUg3L4hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(data[\"lifeExp\"])\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8KH4-zL2l26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data[\"lifeExp\"].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URsgFaai2CK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"Median: \", data[\"lifeExp\"].median())\n",
        "#print(\"Mode: \", data[\"lifeExp\"].mode())\n",
        "#print(\"Variance: \", data[\"lifeExp\"].var())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXFm5_j7L4hj",
        "colab_type": "text"
      },
      "source": [
        "The probability distribution estimated in the graph above is an important source of information about the data.\n",
        "\n",
        "We can compare it with a **normal distribution** using the `norm` method of the `scipy` library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I45uq3q_L4hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw-2NqWYL4hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(data[\"lifeExp\"], fit=norm)\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCz2t6ti_5Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do the same analysis for the feature \"gdpPercap\"\n",
        "\n",
        "#data['gdpPercap'].hist(bins=50)\n",
        "#plt.xlabel(\"GDP per capita\", fontsize=15)\n",
        "#plt.ylabel(\"Frequency\",fontsize=15)\n",
        "#plt.title(\"GDP per capita distribution\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfjXLEFZAmF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sns.distplot(data[\"gdpPercap\"], fit=norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WvlxccQA7P4D"
      },
      "source": [
        "In this case, we see that the actual distribution of the data differs greatly from the normal distribution.\n",
        "\n",
        "In fact, it is more like a **bimodal distribution**, which usually occurs when the data has normally distributed subsets.\n",
        "\n",
        "The following two code cells produce graphs using life expectancy on the African continent and Europe, respectively, showing where the bimodal distribution of the graph above comes from:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_9zMPpq-WZvk",
        "colab": {}
      },
      "source": [
        "africa_data = data.query(\"continent == 'Africa'\")\n",
        "europe_data = data.query(\"continent == 'Europe'\")\n",
        "\n",
        "sns.distplot(europe_data[\"lifeExp\"], fit=norm)\n",
        "sns.distplot(africa_data[\"lifeExp\"], fit=norm)\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution in african and european continents\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3_J7ZCyL4hu",
        "colab_type": "text"
      },
      "source": [
        "In addition to being interesting from a statistical point of view, the graph above is socially impacting and worrying, such a difference in distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vqWvF3L4hv",
        "colab_type": "text"
      },
      "source": [
        "### Boxplots and violin plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mJEBFTkHCsKS"
      },
      "source": [
        "Other types of graphs useful for analyzing distributions are obtained by the `boxplot()` and `violinplot()` methods of `seaborn`.\n",
        "\n",
        "**Boxplot**: shows the quartiles of a series, represented by a box - the ends are the first and third quartiles, while the partition inside the box is the second quartile.\n",
        "\n",
        "This type of graphic is also known as boxes and whiskers (box-and-whiskers), because the minimum and maximum elements are represented by the \"mustaches\" of the box.\n",
        "\n",
        "A particularity of this graph is that the minimum and maximum elements are calculated according to the distance between the first and the third quartiles. Thus, values of the series that extrapolate these extreme values are considered outliers and appear in the boxplot as dots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "poJYkdLgDTnJ",
        "colab": {}
      },
      "source": [
        "sns.boxplot(x=\"lifeExp\", y=\"continent\", data=data.sort_values(\"continent\"))\n",
        "plt.xlabel(\"Life expectancy distribution\", fontsize=15)\n",
        "plt.ylabel(\"Continent\",fontsize=15)\n",
        "plt.title(\"Life expectancy per continent\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zS8Nu9Bjn4Zd"
      },
      "source": [
        "As we can see, Africa is the continent with the lowest life expectancy in general, while Asia is the continent where this data is most dispersed.\n",
        "\n",
        "In the charts above, you can see that there are many outliers.\n",
        "\n",
        "It is interesting to filter the data and analyze the life expectancy per year (for example).\n",
        "\n",
        "The code below produces a boxplot of life expectancy for the year 2007:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wnaTcyOjDZpQ",
        "colab": {}
      },
      "source": [
        "data_2007 = data.query(\"year == 2007\")\n",
        "sns.boxplot(x=\"lifeExp\", y=\"continent\", data=data_2007.sort_values(\"continent\"))\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Continent\",fontsize=15)\n",
        "plt.title(\"Life expectancy per continent (2007)\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9dXYPSOKFofJ"
      },
      "source": [
        "Outlining the year of analysis, we see far fewer outliers.\n",
        "\n",
        "* **Violin plots**: combine the information present in a boxplot and density charts. Despite being extremely rich in information, they are not widespread in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEuRQBBQL4h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.violinplot(x=\"continent\", y=\"lifeExp\", data=data_2007)\n",
        "plt.xlabel(\"Continent\", fontsize=15)\n",
        "plt.ylabel(\"Life expectancy\",fontsize=15)\n",
        "plt.title(\"Life expectancy per continent (2007)\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I32N8qUJ7XQw",
        "colab_type": "text"
      },
      "source": [
        "### Other plots types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RCmCudM7nUg",
        "colab_type": "text"
      },
      "source": [
        "* **Scatterplots**: Visualization of a bivariate distribution is a scatterplot, where each observation is shown with point at the x and y values. \\\\\n",
        "jointplot(): the default kind of plot. \\\\\n",
        "scatterplot(): analogous to a rug plot on two dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fjTjtT3beQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.jointplot(x=\"lifeExp\", y=\"gdpPercap\", data=data);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkR39LFt6lyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.scatterplot(x=\"lifeExp\", y=\"gdpPercap\", data=data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDqfLoQqBFrp",
        "colab_type": "text"
      },
      "source": [
        "* **Categorical scatterplots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlWs9opgBqaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.catplot(x=\"continent\", y=\"gdpPercap\", data=data);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPvGPqiFC9X8",
        "colab_type": "text"
      },
      "source": [
        "As the size of the dataset grows, categorical scatter plots become limited in the information they can provide about the distribution of observations/values within each category. When this happens, bloxplots and violin plots are better ways for summarizing the distributional information in ways that facilitate easy comparisons across the category levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-hgvnjQhXOx",
        "colab_type": "text"
      },
      "source": [
        "* Conclusions:\n",
        "\n",
        "Understanding our data and how this data is grouped is the first step in data science pipelines;\n",
        "\n",
        "Is truly important to stay alert to our data and how will be made it is organisation and visualisation to get **significant results** on our analyses;\n",
        "\n",
        "To carry out these analyses, it is necessary to use measurements, distributions, relations and transformation with our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Tvkgz3jqrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}