{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data analysis and presentation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUWprNFrL4dp",
        "colab_type": "text"
      },
      "source": [
        "# Data analysis and presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Fgl4oFL4dy",
        "colab_type": "text"
      },
      "source": [
        "## Preparation for analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHpX-aUaL4d1",
        "colab_type": "text"
      },
      "source": [
        "Everytime you want to explore and extract information from a dataset, first you need to understand what kind of information can be obtained from the available data. In general, data is classified as:\n",
        "\n",
        "**Numerical data:** Also known as quantitative, they represent counts or measures, like age, height or weight. With this type of data, we can do statistical analysis and determine mean, median, standard deviation, etc. This type can de subdivided into two groups:\n",
        "\n",
        "*   **Discrete:** Represented by integer numbers (ex: Age).\n",
        "*   **Continuous:** Can assume any real value (ex: Weight, height).\n",
        "\n",
        "**Categorical Data:** Also known as qualitative, they represent non-numerical characteristcs. They can be:\n",
        "\n",
        "*   **Ordinal:** Type of data that can be ordered in some way that makes sense (ex.: Age range, stages of a disease, dates).\n",
        "*   **Nominal:** Are basically defined by names, with no specif order (ex: Blood type, race, sex, yes/no).\n",
        "\n",
        "\n",
        "> Check [this video]([https://www.youtube.com/watch?v=GlgA8OMgLxE]) for a nice explanation on these types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2leZMAVKL4d8",
        "colab_type": "text"
      },
      "source": [
        "### Invalid or missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO_qHTn0L4eB",
        "colab_type": "text"
      },
      "source": [
        "Everytime a dataset is collected, a number of procedures must to be done before we extract any relevant and reliable information. In the previous notebooks, we've seen how to start the data exploration with Pandas. However, once we have the created a dataframe, we need to check the integrity of the data and clean it before we can proceed to analysis. According to [IBM Data Analytics](https://www.ibm.com/cloud/blog/ibm-data-catalog-data-scientists-productivity), 80% of the time spent on a dataset is spent cleaning up the data.\n",
        "\n",
        "Treating data that is missing or invalid is an important stage in data cleaning (if some data can't be used in the analysis, it's missing). We're going to use a small [dataset](https://raw.githubusercontent.com/dataoptimal/posts/master/data%20cleaning%20with%20python%20and%20pandas/property%20data.csv), that is big enough to understand how to deal with missing data. Run the cells below to import the example data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_y0lkgdL4eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdGUX6EdL4eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data = pd.read_csv('https://raw.githubusercontent.com/dataoptimal/posts/master/data%20cleaning%20with%20python%20and%20pandas/property%20data.csv',sep=',')\n",
        "missing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF60BY6qL4ee",
        "colab_type": "text"
      },
      "source": [
        "Notice the invalid data in the `DataFrame` above, some of which Pandas can detect and label as `NaN`. We can use the `isna()` method identify missing value in a series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdwJOwPQL4eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data['NUM_BATH'].isna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T7-KkV2L4es",
        "colab_type": "text"
      },
      "source": [
        "See that the `isna()` method returns `True` missing values in a given `Series`. However, it's not practical to manually apply this method to every feature. Instead, we combine the `sum()` method with the result of the `isna()` method applied to the dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-d43AbeL4ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU4VnSmFL4e2",
        "colab_type": "text"
      },
      "source": [
        "Pandas isn't always able to identify invalid data. On our example, the `NUM_BEDROOMS` feature presents an `'na'` value, whereas feature `SQ_FT` presents a `'--'` value. In this case, we can use the `unique()` or `value_counts()` methods to see the values from a series:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQ0LORTL4e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[\"NUM_BEDROOMS\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWfWmwAsL4fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[\"SQ_FT\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzghO0QIL4fH",
        "colab_type": "text"
      },
      "source": [
        "Another source of invalid data happens when the data does not respect the **domain** of the feature. Feature `OWN_OCCUPIED` should contain values ​​in the format `Y` or `N`, but we see value `12` for a given sample. In this case, we can use the `isin()` and `all()` methods too see if all values in a series respect its domain:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDw9x213mLbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[\"OWN_OCCUPIED\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2pwSiLNq_Z7",
        "colab_type": "text"
      },
      "source": [
        "* The `isin()` method returns `True` for each value in a series that respects a given domain, and `False` otherwise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jg9PVneL4fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "domain_condition = missing_data[\"OWN_OCCUPIED\"].isin([\"Y\",\"N\"])\n",
        "domain_condition.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQBZ7pqrrDNh",
        "colab_type": "text"
      },
      "source": [
        "* The `all()` method evaluates if all values in the new series equal `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vIoYTcrrEh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all(domain_condition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIC4XZ5bPNGS",
        "colab_type": "text"
      },
      "source": [
        "To identify which data from `\"OWN_OCCUPIED\"` violate the given condition, we can invert the condition using the `~` (not) operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJHXm9bVL4fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data[~domain_condition]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qNSg1qIL4fY",
        "colab_type": "text"
      },
      "source": [
        "## Starting the analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP9JFgyKL4fa",
        "colab_type": "text"
      },
      "source": [
        "For this part of the tutorial, we are gonna load the data from an URL using Pandas. We can do this using the URL as argument to the `read_csv()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IvRWAQofrpLA",
        "colab": {}
      },
      "source": [
        "url_data = 'http://bit.ly/2cLzoxH'\n",
        "data = pd.read_csv(url_data)\n",
        "data.head(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcl-3Y4RubSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take a quick look at the data types\n",
        "# data.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhvfKoZU-hB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data[\"continent\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPRXqHsVL4fh",
        "colab_type": "text"
      },
      "source": [
        "For this dataset, we have no missing or invalid data, so we can start our analysis. The first set of tools that we can use come from **descriptive statistics**. Pandas offer the main **central** and **dispersion** measures, which we can apply to any numeric data series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwgOpZdLL4fj",
        "colab_type": "text"
      },
      "source": [
        "### Central measures\n",
        "\n",
        "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTor8kh4Rw5xvOcKII09VV1WANhpsjp_WIB6-oQv4IpjfUWZTTn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNGpvCHgL4fl",
        "colab_type": "text"
      },
      "source": [
        "* **Mean**: The sum of all values, divided by the number of samples in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZA059wL4fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0dlTWlOL4fr",
        "colab_type": "text"
      },
      "source": [
        "* **Median**: The value that separates the bigger half from the smallest half on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6BTNx0hL4fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].median()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eekJ8I1UL4fx",
        "colab_type": "text"
      },
      "source": [
        "* **Mode**: The value(s) that appear more frequently in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS-E95i1L4fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].mode()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFAtr7ULL4f4",
        "colab_type": "text"
      },
      "source": [
        "### Dispersion Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us_pPKC4L4f5",
        "colab_type": "text"
      },
      "source": [
        "**Variance**: Indicates the data scattering in a series, representing the mean distance from each value in series to the mean of the series. Each distance is squared, so that positive and negative distances do not cancel each other. Due to squaring, the scale of the variance does not match variance of the series. Ovearll, a low variance indicates that the values from the series tend to be closer to the mean. A high variance indicates that the values are scattered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXQWRiJL4f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].var()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr48uJXwL4gB",
        "colab_type": "text"
      },
      "source": [
        "**Standard deviation**: Square root of the variance. Retains all its properties, but presents the same scale as the series: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i38lCnbZL4gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12tsWb4bL4gH",
        "colab_type": "text"
      },
      "source": [
        "**Quantiles**: Partition the ordered values in a series. A 25% quantile indicates that 25% of the series values ​​are less than that quantile. By convention, ***quartiles*** are the 25%, 50% and 75% quantiles, also known as first, second and third quartiles:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb4SSYvdL4gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].quantile(0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0A_xffYL4gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_quartile = data.query(f\"year < {data['year'].quantile(0.25)}\")\n",
        "first_quartile.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TNF9SjNIL4gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3FBtCgHu8P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing for others quartiles\n",
        "# data[\"year\"].quantile(0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJaB2JezuyHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# second_quartile = data.query(f\"year < {data['year'].quantile(0.5)}\")\n",
        "# second_quartile.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5n8HvrYL4gc",
        "colab_type": "text"
      },
      "source": [
        "### Other descriptive statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4whhc4L4gd",
        "colab_type": "text"
      },
      "source": [
        "* `describe()`: Brings together many descriptive measures about the data, including the `count()`, `min()` and `max()` methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu-NRWZrL4gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weIrWGPeL4gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8D8V-sVL4go",
        "colab_type": "text"
      },
      "source": [
        "* `nunique()`: Informs the number of distinct values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHQAU6xOL4gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiYwdjY_L4gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsxPrw_gL4gx",
        "colab_type": "text"
      },
      "source": [
        "* `sort_values()`: Sorts the values of a `DataFrame` or `Series`, in ascending or descending order. When using the `sort_values()` method of the `DataFrame`, we can specify multiple columns to sort. In this case, ties on the first column will be solved based on the second column, and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_osXt0cL4g0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"year\"].sort_values().head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL7kQVvpL4g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.sort_values(by=['year','country'], ascending=False).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma_laG1zyPkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data.sort_values(by=['year','lifeExp'], ascending=True).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwABO3JgL4g-",
        "colab_type": "text"
      },
      "source": [
        "## Data Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ni0vgAIHiFI"
      },
      "source": [
        "Analyzing central and dispersion measures is usually deepened by data visualization. To start, let's load the necessary libraries:\n",
        "- `matplotlib` is a library that serves exclusively to create graphics.\n",
        "- `seaborn` is a library designed to create statistical graphs in Python. It's built on Matplotlib and it's integrated with Pandas data structures.\n",
        "\n",
        "By convention, we only load the `pyplot` module from the `matplotlib` library and call it `plt`. In the case of `seaborn`, we load the entire library, call it `sns` and use its `set()` method to put its initial settings into effect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_PDGogQn3QS",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kIbzhXQ000XQ"
      },
      "source": [
        "### Histograms\n",
        "\n",
        "It's quite easy to construct a histogram with Pandas and matplotlib. However, we need to understand exactly what is being built. In the example below, we'll use the `lifeExp` feature, which shows the life expectancy per year. With the `hist(bins = 100)` method, we produce the histogram with 100 different value ranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NwLUT8xptz_9",
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JKLxZZdx4sLT"
      },
      "source": [
        "Below, we can see the (extreme) effect of building a histogram with few value ranges (only two, in this case).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ooQ_pCJKuMX-",
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lyarbic35AgQ"
      },
      "source": [
        "The next case is the opposite of the above: many value ranges (1000) make understanding the plot very difficult."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aj6a95vvu4Ie",
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCdxMt0PzARd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ploting the data analysis of the feature 'year' shows that not all information can be analyzed using a histogram\n",
        "#data[\"year\"].hist(bins=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-G0sC0zyAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data[\"year\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AqnPTNI0P7vL"
      },
      "source": [
        "The standard matplotlib  histogram is basic and only serves for a quick look at the data distribution. Note that there are no names on the x and y axes, and that there is an x-axis region being presented even if there is no data on it.\n",
        "\n",
        "We can customize the histogram using the following parameters:\n",
        "  - `xlabelsize` and `ylabelsize` set the font size on the axes;\n",
        "  - `xlabel` and `ylabel` change the title of the axis and the size of that text;\n",
        "  - `xlim` determines the lower and upper limits of the horizontal axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7AsoMmeHP_kh",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "data['lifeExp'].hist(bins=100, grid=False, xlabelsize=12, ylabelsize=12)\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution\", fontsize=17)\n",
        "plt.xlim([22.0,90.0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20_-XPE6L4hd",
        "colab_type": "text"
      },
      "source": [
        "Although it is convenient to use the `hist()` method directly from a series, the `seaborn` `distplot()` method is much more powerful. In addition to presenting a histogram of the data, `distplot()` estimates a **probability distribution** of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4bINUg3L4hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(data[\"lifeExp\"])\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8KH4-zL2l26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data[\"lifeExp\"].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URsgFaai2CK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Median: \", data[\"lifeExp\"].median())\n",
        "# print(\"Mode: \", data[\"lifeExp\"].mode())\n",
        "# print(\"Variance: \", data[\"lifeExp\"].var())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXFm5_j7L4hj",
        "colab_type": "text"
      },
      "source": [
        "The probability distribution estimated in the graph above is an important source of information about the data. We can compare it with a **normal distribution** using the `norm` method of the `scipy` library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I45uq3q_L4hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw-2NqWYL4hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(data[\"lifeExp\"], fit=norm)\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCz2t6ti_5Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do the same analysis for the feature \"gdpPercap\"\n",
        "\n",
        "# data['gdpPercap'].hist(bins=50)\n",
        "# plt.xlabel(\"GDP per capita\", fontsize=15)\n",
        "# plt.ylabel(\"Frequency\",fontsize=15)\n",
        "# plt.title(\"GDP per capita distribution\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfjXLEFZAmF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(data[\"gdpPercap\"], fit=norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WvlxccQA7P4D"
      },
      "source": [
        "In this case, we see that the actual distribution of the data differs greatly from the normal distribution. In fact, it is more like a **bimodal distribution**, which usually occurs when the data has normally distributed subsets.\n",
        "\n",
        "The following two code cells produce graphs using life expectancy on Africa and Europe, respectively, showing where the bimodal distribution of the graph above comes from:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_9zMPpq-WZvk",
        "colab": {}
      },
      "source": [
        "africa_data = data.query(\"continent == 'Africa'\")\n",
        "europe_data = data.query(\"continent == 'Europe'\")\n",
        "\n",
        "sns.distplot(europe_data[\"lifeExp\"], fit=norm)\n",
        "sns.distplot(africa_data[\"lifeExp\"], fit=norm)\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\",fontsize=15)\n",
        "plt.title(\"Life expectancy distribution in african and european continents\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3_J7ZCyL4hu",
        "colab_type": "text"
      },
      "source": [
        "In addition to being interesting from a statistical point of view, the graph above is socially impacting and worrying, given such a difference in distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vqWvF3L4hv",
        "colab_type": "text"
      },
      "source": [
        "### Boxplots and violin plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mJEBFTkHCsKS"
      },
      "source": [
        "The `boxplot()` and `violinplot()` methods of `seaborn` produce other types of graphs useful for distribution analysis:\n",
        "\n",
        "**Boxplot**: shows the quartiles of a series, represented by a box. The box edges are the first and third quartiles, while the partition inside the box is the second quartile. This type of graphic is also known as boxes and whiskers (box-and-whiskers), because the minimum and maximum elements are represented by the \"whiskers\" of the box.\n",
        "\n",
        "A particularity of this graph is that the minimum and maximum elements are calculated according to the distance between the first and the third quartiles. Values of the series that extrapolate these extreme values are considered outliers and appear in the boxplot as dots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "poJYkdLgDTnJ",
        "colab": {}
      },
      "source": [
        "sns.boxplot(x=\"lifeExp\", y=\"continent\", data=data.sort_values(\"continent\"))\n",
        "plt.xlabel(\"Life expectancy distribution\", fontsize=15)\n",
        "plt.ylabel(\"Continent\",fontsize=15)\n",
        "plt.title(\"Life expectancy per continent\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zS8Nu9Bjn4Zd"
      },
      "source": [
        "As we can see, Africa is the continent with the lowest life expectancy in general, while Asia is the continent where this data is most scatterd. In the charts above, you can see that there are many outliers. We can further investigate the data filtering the life expectancy per year. The code below produces a boxplot of life expectancy for the year 2007:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wnaTcyOjDZpQ",
        "colab": {}
      },
      "source": [
        "data_2007 = data.query(\"year == 2007\")\n",
        "sns.boxplot(x=\"lifeExp\", y=\"continent\", data=data_2007.sort_values(\"continent\"))\n",
        "plt.xlabel(\"Life expectancy\", fontsize=15)\n",
        "plt.ylabel(\"Continent\",fontsize=15)\n",
        "plt.title(\"Life expectancy per continent (2007)\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9dXYPSOKFofJ"
      },
      "source": [
        "Outlining the year of analysis, we see far fewer outliers.\n",
        "\n",
        "* **Violin plots**: combine the information present in a boxplot and density charts. Despite being extremely rich in information, they are not widespread in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEuRQBBQL4h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.violinplot(x=\"continent\", y=\"lifeExp\", data=data_2007)\n",
        "plt.xlabel(\"Continent\", fontsize=15)\n",
        "plt.ylabel(\"Life expectancy\",fontsize=15)\n",
        "plt.title(\"Life expectancy per continent (2007)\", fontsize=17)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}